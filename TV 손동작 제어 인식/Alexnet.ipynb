{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4854,"status":"ok","timestamp":1675931518944,"user":{"displayName":"유승우","userId":"01769480604712184344"},"user_tz":-540},"id":"UgF4qn3M1F8Q","outputId":"30ab75db-bdb2-4d15-ba80-ba1ad4de566d"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import datasets, transforms\n","from torch.nn.modules.pooling import MaxPool2d\n","from torch.nn.modules.normalization import LocalResponseNorm\n","devices = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(devices)"]},{"cell_type":"markdown","metadata":{"id":"tFIkGblB3Iqi"},"source":["### **Dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FA2Ydupo15Ja"},"outputs":[],"source":["# 데이터 transform 정의\n","transform = transforms.Compose([transforms.Resize(256),\n","                                transforms.RandomCrop(227),\n","                                transforms.ToTensor(),\n","                                # transforms.RandomHorizontalFlip(1),\n","                                transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n","                                \n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fBFT292u2vOR"},"outputs":[],"source":["# 데이터셋 저장\n","ci_train = datasets.CIFAR10('~/data/', train=True, transform=transform,download=True)\n","ci_test = datasets.CIFAR10('~/data/', train=True, transform=transform,download=True)\n","print(\"ci_train:\\n\", ci_train,'\\n')\n","print(\"ci_test:\\n\", ci_test,'\\n')"]},{"cell_type":"markdown","metadata":{"id":"ndhR9JS53qA9"},"source":["### **Data Iterator**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fP-ofNBr2scr"},"outputs":[],"source":["batch_size = 256\n","train_iter = torch.utils.data.DataLoader(ci_train, batch_size=batch_size, shuffle=True, num_workers=1)\n","test_iter = torch.utils.data.DataLoader(ci_train, batch_size=batch_size, shuffle=True, num_workers=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6aCIVjZoo10O"},"outputs":[],"source":["#이미지 확인하기 \n","def imshow(img):\n","  img = img / 2 + 0.5 \n","  npimg = img.numpy()\n","  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","  plt.show() \n","\n","# 학습용 이미지 뽑기\n","dataiter = iter(train_iter)\n","images, labels = dataiter.next() \n","\n","# 이미지 보여주기 \n","imshow(torchvision.utils.make_grid(images)) \n","torchvision.utils.make_grid(images).shape\n","\n","# 이미지별 라벨 (클래스) 보여주기 \n","# print(' '.join('%5s' % [labels[j]] for j in range(4)))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"lQZMp9RR4gIA"},"source":["### **Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P3L-XPbH4pwR"},"outputs":[],"source":["class AlexNet(nn.Module):\n","  def __init__(self, input_size=227, num_classes = 10):\n","    super(AlexNet, self).__init__()\n","\n","  # Convolution layer 정의\n","    self.layers = nn.Sequential(\n","        # 1 conv\n","        nn.Conv2d(in_channels=3,out_channels=96,kernel_size=11,stride=4,padding=0),\n","        nn.ReLU(inplace=True),\n","        # nn.LocalResponseNorm(size =5, alpha=0.0001, beta=0.75, k=2),\n","        nn.BatchNorm2d(96),\n","        nn.MaxPool2d(kernel_size=3,stride=2),\n","\n","        # 2 conv\n","        nn.Conv2d(in_channels=96, out_channels=256,kernel_size=5,stride=1,padding=2),\n","        nn.ReLU(inplace=True),\n","        # nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n","        nn.BatchNorm2d(256),\n","        nn.MaxPool2d(kernel_size=3,stride=2),\n","\n","        # 3 conv\n","        nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3,stride=1,padding=1),\n","        nn.ReLU(inplace=True),\n","        \n","\n","        # 4 conv\n","        nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3,stride=1,padding=1),\n","        nn.ReLU(inplace=True),\n","\n","\n","        # 5 conv\n","        nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3,stride=1,padding=1),\n","        nn.ReLU(inplace=True),\n","        nn.MaxPool2d(kernel_size=3, stride=2)\n","    )\n","\n","    self.fclayer = nn.Sequential(\n","        # 6 fc layer\n","        # nn.Dropout(0.5),\n","        nn.Linear(6*6*256, 4096),\n","        nn.ReLU(inplace=True),\n","        \n","        \n","        # 7 fc layer\n","        # nn.Dropout(0.5),\n","        nn.Linear(4096,4096),\n","        nn.ReLU(inplace=True),\n","       \n","\n","        # 8 fc layer\n","        nn.Linear(4096,num_classes)\n","    )\n","\n","    # 표준화 및 bias 초기화\n","    for layer in self.layers:\n","      if isinstance(layer, nn.Conv2d):\n","        nn.init.normal_(layer.weight, mean=0, std=0.01)\n","        nn.init.constant_(layer.bias,0)\n","\n","    # nn.init.constant_(self.layers[4].bias,1)\n","    # nn.init.constant_(self.layers[10].bias,0.8)\n","    # nn.init.constant_(self.layers[12].bias,0.6)\n","      \n","  def forward(self, train):\n","    output = self.layers(train)\n","    output = torch.flatten(output,1)\n","    output = self.fclayer(output)\n","      \n","    return output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1176,"status":"ok","timestamp":1645531089783,"user":{"displayName":"유승우","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01769480604712184344"},"user_tz":-540},"id":"oRWxHXgOATgJ","outputId":"ba25519a-3499-43a4-9070-a3494487b55e"},"outputs":[{"data":{"text/plain":["AlexNet(\n","  (layers): Sequential(\n","    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n","    (1): ReLU(inplace=True)\n","    (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (5): ReLU(inplace=True)\n","    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (fclayer): Sequential(\n","    (0): Linear(in_features=9216, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Linear(in_features=4096, out_features=4096, bias=True)\n","    (3): ReLU(inplace=True)\n","    (4): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n",")"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["alexnet = AlexNet(227,10)\n","alexnet.to(devices)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vwpAPKB8Fszt"},"outputs":[],"source":["optimizer = optim.SGD(alexnet.parameters(),lr=0.01,momentum=0.9, weight_decay = 0.0005)\n","criterion = nn.CrossEntropyLoss().to(devices)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5932cwniG-uT"},"outputs":[],"source":["from tqdm.notebook import tqdm\n","import time\n","\n","start_time = time.time()\n","min_loss = int(1e9)\n","history = []\n","accuracy = []\n","\n","for epoch in range(20):\n","    epoch_loss = 0\n","    tk0 = tqdm(train_iter, total=len(train_iter),leave=False)\n","    for step, (inputs, labels) in enumerate(tk0, 0):\n","        inputs, labels = inputs.to(devices), labels.to(devices)\n","        outputs = alexnet(inputs)\n","        optimizer.zero_grad()\n","\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        history.append(loss.item())\n","    \n","    class_correct = list(0. for i in range(1000))\n","    class_total = list(0. for i in range(1000))\n","    \n","    with torch.no_grad():\n","        for data in test_iter:\n","            images, labels = data\n","            images = images.to(devices)\n","            labels = labels.to(devices)\n","            outputs = alexnet(images)\n","            _, predicted = torch.max(outputs, 1)\n","            c = (predicted == labels).squeeze()\n","            for i in range(labels.size()[0]):\n","                label = labels[i].item()\n","                class_correct[label] += c[i].item()\n","                class_total[label] += 1\n","\n","    accuracy.append(sum(class_correct) /sum(class_total)*100)\n","    tqdm.write(\"[Epoch : %d] train_loss : %.5f test_acc: %.2f\" % \n","               (epoch +1 , epoch_loss/196, sum(class_correct) /sum(class_total)*100))\n","    \n","    if min_loss < epoch_loss:\n","      count+=1\n","      if count > 10:\n","        for g in optimizer.param_groups:\n","          g['lr']/=10\n","    else:\n","      min_loss = epoch_loss\n","      count = 0\n","\n","print(time.time()-start_time)\n","print(\"Done\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NTlfXfMsA6vq"},"outputs":[],"source":["plt.plot(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zG5bdjcMQY-9"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyMYBX7g4QOSEMJCAOpuqjZ0"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}