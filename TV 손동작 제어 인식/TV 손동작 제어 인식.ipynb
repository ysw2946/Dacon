{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPOQ91ghIKkhYMJ7/9Qmrsx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"c1889fddb5424ba8913e7c80a59981a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d7183b7b46c43bc84594d844efe650a","IPY_MODEL_05941cf3b87c472a892a93211d0c1999","IPY_MODEL_c8c259bad97743589e8e284f2f2114ec"],"layout":"IPY_MODEL_ac2cdf2ece7b42479ebe29b162079d87"}},"9d7183b7b46c43bc84594d844efe650a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb60644bd05e45f397bc209ac43f6ee3","placeholder":"​","style":"IPY_MODEL_f5899078377744c48dd22fb29a33b47d","value":"100%"}},"05941cf3b87c472a892a93211d0c1999":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_592f80d4b10f46cbb94a98dd87ce2df0","max":39,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e8759470a75e4aeaa3c06f2233e563c8","value":39}},"c8c259bad97743589e8e284f2f2114ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac2aed29808745918357bd9896393fab","placeholder":"​","style":"IPY_MODEL_65a2c5c2276e4390b13dc4b89bd9f81c","value":" 39/39 [02:38&lt;00:00,  3.22s/it]"}},"ac2cdf2ece7b42479ebe29b162079d87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb60644bd05e45f397bc209ac43f6ee3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5899078377744c48dd22fb29a33b47d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"592f80d4b10f46cbb94a98dd87ce2df0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8759470a75e4aeaa3c06f2233e563c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ac2aed29808745918357bd9896393fab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65a2c5c2276e4390b13dc4b89bd9f81c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/데이콘/TV 손동작 제어 인식/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yoRgrCk4nJ9y","executionInfo":{"status":"ok","timestamp":1674723009115,"user_tz":-540,"elapsed":3613,"user":{"displayName":"유승우","userId":"01769480604712184344"}},"outputId":"bbed1529-e6b5-4d39-cec2-67975ee8f4af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/데이콘/TV 손동작 제어 인식\n"]}]},{"cell_type":"code","source":["!pip install pytorchvideo"],"metadata":{"id":"PQV4SDYw5IYM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import cv2\n","import os\n","\n","from tqdm.auto import tqdm\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from torchvision import transforms\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","import matplotlib.pyplot as plt\n","CFG = {\n","    'FPS':30,\n","    'IMG_SIZE':128,\n","    'EPOCHS':100,\n","    'LEARNING_RATE':3e-4,\n","    'BATCH_SIZE':4,\n","    'SEED':42\n","}\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ISI7j6-nifo","executionInfo":{"status":"ok","timestamp":1674723011163,"user_tz":-540,"elapsed":2051,"user":{"displayName":"유승우","userId":"01769480604712184344"}},"outputId":"fc30a0c2-6588-45ea-ee93-4e9982464889"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('./train.csv')\n","train, val, _, _ = train_test_split(df, df['label'], test_size=0.2, random_state=42)"],"metadata":{"id":"QP00H5ADpQe1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transform = A.Compose([A.Resize(224,224),\n","                      # A.RandomCrop(224,224),\n","                      # A.HorizontalFlip(p=0.2),\n","                      # A.RandomBrightnessContrast(p=0.2),\n","                      A.Normalize(mean = (0.485, 0.456, 0.406),std = (0.229, 0.224, 0.225))\n","                      ])"],"metadata":{"id":"ekeCWsOPYOCM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, video_path_list, label_list, transform=None):\n","        self.video_path_list = video_path_list\n","        self.label_list = label_list\n","        self.transform = transform\n","        \n","    def __getitem__(self, index):\n","        frames = self.get_video(self.video_path_list[index])\n","        \n","        if self.label_list is not None:\n","            label = self.label_list[index]\n","            return frames, label\n","        else:\n","            return frames\n","        \n","    def __len__(self):\n","        return len(self.video_path_list)\n","    \n","    def get_video(self, path):\n","        frames = []\n","        cap = cv2.VideoCapture(path)\n","        for _ in range(CFG['FPS']):\n","            _, img = cap.read()\n","            # img = cv2.resize(img, (CFG['IMG_SIZE'], CFG['IMG_SIZE']))\n","            # img = img / 255.\n","\n","            if self.transform:\n","              img = self.transform(image=img)['image']\n","\n","            frames.append(img)\n","        return torch.FloatTensor(np.array(frames)).permute(3,0,1,2)"],"metadata":{"id":"YBm7d6d4pjZp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = CustomDataset(train['path'].values, train['label'].values,transform)\n","train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n","\n","val_dataset = CustomDataset(val['path'].values, val['label'].values,transform)\n","val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"],"metadata":{"id":"FkxluW-Pp9cf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"1Zb6HWRfPC10"}},{"cell_type":"code","source":["import math\n","from functools import partial\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","def get_inplanes():\n","    return [64, 128, 256, 512]\n","\n","\n","def conv3x3x3(in_planes, out_planes, stride=1):\n","    return nn.Conv3d(in_planes,\n","                     out_planes,\n","                     kernel_size=3,\n","                     stride=stride,\n","                     padding=1,\n","                     bias=False)\n","\n","\n","def conv1x1x1(in_planes, out_planes, stride=1):\n","    return nn.Conv3d(in_planes,\n","                     out_planes,\n","                     kernel_size=1,\n","                     stride=stride,\n","                     bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1, downsample=None):\n","        super().__init__()\n","\n","        self.conv1 = conv3x3x3(in_planes, planes, stride)\n","        self.bn1 = nn.BatchNorm3d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm3d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1, downsample=None):\n","        super().__init__()\n","\n","        self.conv1 = conv1x1x1(in_planes, planes)\n","        self.bn1 = nn.BatchNorm3d(planes)\n","        self.conv2 = conv3x3x3(planes, planes, stride)\n","        self.bn2 = nn.BatchNorm3d(planes)\n","        self.conv3 = conv1x1x1(planes, planes * self.expansion)\n","        self.bn3 = nn.BatchNorm3d(planes * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, block_inplanes, n_input_channels=3, conv1_t_size=7, conv1_t_stride=1, no_max_pool=False, shortcut_type='B', widen_factor=1.0, n_classes=5):\n","        super().__init__()\n","\n","        block_inplanes = [int(x * widen_factor) for x in block_inplanes]\n","\n","        self.in_planes = block_inplanes[0]\n","        self.no_max_pool = no_max_pool\n","\n","        self.conv1 = nn.Conv3d(n_input_channels,\n","                               self.in_planes,\n","                               kernel_size=(conv1_t_size, 7, 7),\n","                               stride=(conv1_t_stride, 2, 2),\n","                               padding=(conv1_t_size // 2, 3, 3),\n","                               bias=False)\n","        self.bn1 = nn.BatchNorm3d(self.in_planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, block_inplanes[0], layers[0],\n","                                       shortcut_type)\n","        self.layer2 = self._make_layer(block,\n","                                       block_inplanes[1],\n","                                       layers[1],\n","                                       shortcut_type,\n","                                       stride=2)\n","        self.layer3 = self._make_layer(block,\n","                                       block_inplanes[2],\n","                                       layers[2],\n","                                       shortcut_type,\n","                                       stride=2)\n","        self.layer4 = self._make_layer(block,\n","                                       block_inplanes[3],\n","                                       layers[3],\n","                                       shortcut_type,\n","                                       stride=2)\n","\n","        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n","        self.fc = nn.Linear(block_inplanes[3] * block.expansion, n_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv3d):\n","                nn.init.kaiming_normal_(m.weight,\n","                                        mode='fan_out',\n","                                        nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm3d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def _downsample_basic_block(self, x, planes, stride):\n","        out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n","        zero_pads = torch.zeros(out.size(0), planes - out.size(1), out.size(2),\n","                                out.size(3), out.size(4))\n","        if isinstance(out.data, torch.cuda.FloatTensor):\n","            zero_pads = zero_pads.cuda()\n","\n","        out = torch.cat([out.data, zero_pads], dim=1)\n","\n","        return out\n","\n","    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n","        downsample = None\n","        if stride != 1 or self.in_planes != planes * block.expansion:\n","            if shortcut_type == 'A':\n","                downsample = partial(self._downsample_basic_block,\n","                                     planes=planes * block.expansion,\n","                                     stride=stride)\n","            else:\n","                downsample = nn.Sequential(\n","                    conv1x1x1(self.in_planes, planes * block.expansion, stride),\n","                    nn.BatchNorm3d(planes * block.expansion))\n","\n","        layers = []\n","        layers.append(\n","            block(in_planes=self.in_planes,\n","                  planes=planes,\n","                  stride=stride,\n","                  downsample=downsample))\n","        self.in_planes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.in_planes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        if not self.no_max_pool:\n","            x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","\n","        return x\n","\n"],"metadata":{"id":"ntk8eqakxxWh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, optimizer, train_loader, val_loader, scheduler, device):\n","    model.to(device)\n","    criterion = nn.CrossEntropyLoss().to(device)\n","    \n","    best_val_score = 0\n","    best_model = None\n","    best_epoch = 0\n","    for epoch in range(1, CFG['EPOCHS']+1):\n","        model.train()\n","        train_loss = []\n","        for videos, labels in tqdm(iter(train_loader)):\n","            videos = videos.to(device)\n","            labels = labels.to(device)\n","            \n","            optimizer.zero_grad()\n","            \n","            output = model(videos)\n","            loss = criterion(output, labels)\n","            \n","            loss.backward()\n","            optimizer.step()\n","            \n","            train_loss.append(loss.item())\n","                    \n","        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n","        _train_loss = np.mean(train_loss)\n","        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val F1 : [{_val_score:.5f}]')\n","        \n","        if scheduler is not None:\n","            scheduler.step(_val_score)\n","            \n","        if best_val_score < _val_score:\n","            best_val_score = _val_score\n","            best_model = model\n","            best_epoch = epoch\n","            print('best model found!')\n","            torch.save(model.state_dict(), os.path.join(\"best-model.pt\"))     \n","\n","\n","    print('best F1 : ', best_val_score, ', best epoch : ', best_epoch)\n","    return best_model\n","\n","def validation(model, criterion, val_loader, device):\n","    model.eval()\n","    val_loss = []\n","    preds, trues = [], []\n","    \n","    with torch.no_grad():\n","        for videos, labels in tqdm(iter(val_loader)):\n","            videos = videos.to(device)\n","            labels = labels.to(device)\n","            \n","            logit = model(videos)\n","            \n","            loss = criterion(logit, labels)\n","            \n","            val_loss.append(loss.item())\n","            \n","            preds += logit.argmax(1).detach().cpu().numpy().tolist()\n","            trues += labels.detach().cpu().numpy().tolist()\n","        \n","        _val_loss = np.mean(val_loss)\n","    \n","    _val_score = f1_score(trues, preds, average='macro')\n","    return _val_loss, _val_score"],"metadata":{"id":"iEoGbeOpsN05"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kwargs  =  {'n_input_channels' : 3,\n","        'conv1_t_size' : 7,\n","        'conv1_t_stride' : 1,\n","        'no_max_pool' : False,\n","        'shortcut_type' : 'B',\n","        'widen_factor' : 1.0,\n","        'n_classes' : 5}"],"metadata":{"id":"TZ1FoV4GtN7w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_depth = 50"],"metadata":{"id":"91d2_uZuxy-9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if model_depth == 10:\n","    model = ResNet(BasicBlock, [1, 1, 1, 1], get_inplanes(), **kwargs)\n","elif model_depth == 18:\n","    model = ResNet(BasicBlock, [2, 2, 2, 2], get_inplanes(), **kwargs)\n","elif model_depth == 34:\n","    model = ResNet(BasicBlock, [3, 4, 6, 3], get_inplanes(), **kwargs)\n","elif model_depth == 50:\n","    model = ResNet(Bottleneck, [3, 4, 6, 3], get_inplanes(), **kwargs)\n","elif model_depth == 101:\n","    model = ResNet(Bottleneck, [3, 4, 23, 3], get_inplanes(), **kwargs)\n","elif model_depth == 152:\n","    model = ResNet(Bottleneck, [3, 8, 36, 3], get_inplanes(), **kwargs)\n","elif model_depth == 200:\n","    model = ResNet(Bottleneck, [3, 24, 36, 3], get_inplanes(), **kwargs)"],"metadata":{"id":"w6RJf-mjs_cI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = torch.optim.AdamW(model.parameters(), lr=CFG[\"LEARNING_RATE\"] ,weight_decay=.0004)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, \n","                                                                 T_mult=2, eta_min=0.00001)"],"metadata":{"id":"EfGQWQhztUmg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"],"metadata":{"id":"cq_4WMNsyFTL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load('./best-model.pt'),strict=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_CHR5jMpm-eP","executionInfo":{"status":"ok","timestamp":1674721362837,"user_tz":-540,"elapsed":1059,"user":{"displayName":"유승우","userId":"01769480604712184344"}},"outputId":"28482bb1-b707-40a5-d798-70342ae53427"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["test = pd.read_csv('./test.csv')\n","\n","test_dataset = CustomDataset(test['path'].values, None, transform)\n","test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"],"metadata":{"id":"8ZmTXEPyyG1L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def inference(model, test_loader, device):\n","    model.to(device)\n","    model.eval()\n","    preds = []\n","    with torch.no_grad():\n","        for videos in tqdm(iter(test_loader)):\n","            videos = videos.to(device)\n","            \n","            logit = model(videos)\n","\n","            preds += logit.argmax(1).detach().cpu().numpy().tolist()\n","    return preds\n","\n","preds = inference(model, test_loader, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["c1889fddb5424ba8913e7c80a59981a8","9d7183b7b46c43bc84594d844efe650a","05941cf3b87c472a892a93211d0c1999","c8c259bad97743589e8e284f2f2114ec","ac2cdf2ece7b42479ebe29b162079d87","cb60644bd05e45f397bc209ac43f6ee3","f5899078377744c48dd22fb29a33b47d","592f80d4b10f46cbb94a98dd87ce2df0","e8759470a75e4aeaa3c06f2233e563c8","ac2aed29808745918357bd9896393fab","65a2c5c2276e4390b13dc4b89bd9f81c"]},"id":"k_vgsRVRzBlt","executionInfo":{"status":"ok","timestamp":1674721558578,"user_tz":-540,"elapsed":158935,"user":{"displayName":"유승우","userId":"01769480604712184344"}},"outputId":"e88f95b4-2894-40b8-8c39-ac98385a3b29"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/39 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1889fddb5424ba8913e7c80a59981a8"}},"metadata":{}}]},{"cell_type":"code","source":["submission = pd.read_csv('./sample_submission.csv')\n","submission['label'] = preds\n","submission.to_csv('./resnet50_20epoch_(224,224).csv',index=False)"],"metadata":{"id":"jQvt5u6jzF4a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"i4nSK4Uh0yK3"},"execution_count":null,"outputs":[]}]}